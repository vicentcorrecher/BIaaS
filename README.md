# Data Val√®ncia Agent  (Analista de Datos Abiertos de Valencia)


**Data Val√®ncia Agent** es una aplicaci√≥n web interactiva desarrollada con Streamlit y potenciada por Modelos de Lenguaje Grandes (LLMs) como Gemini y Llama 3. Su objetivo es permitir a cualquier usuario explorar el [cat√°logo de Datos Abiertos del Ayuntamiento de Valencia](https://valencia.opendatasoft.com/pages/home/?flg=es-es) utilizando lenguaje natural.

La aplicaci√≥n encuentra el dataset m√°s relevante para la consulta del usuario, lo descarga, lo analiza y genera visualizaciones y res√∫menes de forma autom√°tica, actuando como un analista de datos virtual.

---

##  Caracter√≠sticas Principales

-   **B√∫squeda Sem√°ntica**: Utiliza embeddings de sentencias (`sentence-transformers`) y un √≠ndice vectorial (FAISS) para encontrar el dataset m√°s relevante para una consulta en lenguaje natural.
-   **Multi-LLM**: Permite cambiar entre diferentes proveedores de LLM (Google Gemini, Llama 3 a trav√©s de Groq) para la planificaci√≥n y generaci√≥n de insights.
-   **An√°lisis Autom√°tico de Datos**: Identifica autom√°ticamente tipos de columnas (num√©ricas, categ√≥ricas, geoespaciales, temporales).
-   **Generaci√≥n de Visualizaciones**: El LLM planifica y sugiere los gr√°ficos m√°s adecuados (mapas, barras, l√≠neas, etc.) para responder a la consulta del usuario.
-   **Creaci√≥n de Insights**: Un agente LLM interpreta los gr√°ficos y los datos para generar un resumen ejecutivo en texto.
-   **Interfaz Interactiva**: Construida con Streamlit para una experiencia de usuario fluida y conversacional.

---

## üõ†Ô∏è Arquitectura y Tecnolog√≠as

El proyecto sigue una arquitectura modular basada en agentes, donde cada componente tiene una responsabilidad clara:

-   **Frontend**: `Streamlit`
-   **B√∫squeda y RAG (Retrieval-Augmented Generation)**:
    -   **Embeddings**: `sentence-transformers` (modelo `paraphrase-MiniLM-L6-v2`)
    -   **√çndice Vectorial**: `FAISS`
-   **Modelos de Lenguaje (LLMs)**:
    -   `Google Gemini` (a trav√©s de `google-generativeai`)
    -   `Llama 3` (a trav√©s de `groq`)
-   **An√°lisis y Manipulaci√≥n de Datos**: `Pandas`, `NumPy`
-   **Visualizaci√≥n**: `Plotly Express`
-   **Gesti√≥n de Dependencias**: `pip` y `requirements.txt`
-   **Gesti√≥n de Secrets**: `python-dotenv`

---

## ‚öôÔ∏è Instalaci√≥n y Ejecuci√≥n Local

Sigue estos pasos para ejecutar el proyecto en tu m√°quina local.

### Prerrequisitos

-   Python 3.8+
-   Git

### 1. Clonar el Repositorio

```bash
git clone https://github.com/TU_USUARIO/TU_REPOSITORIO.git
cd TU_REPOSITORIO
```


### 2. Crear y activar un entorno virtual
Es una buena pr√°ctica aislar las dependencias del proyecto para evitar conflictos.
```bash
# Crear el entorno virtual
python -m venv venv

# Activar el entorno (en Windows)
.\venv\Scripts\activate

# Activar el entorno (en macOS o Linux)
source venv/bin/activate
```
Sabr√°s que est√° activado porque tu terminal mostrar√° (venv) al principio de la l√≠nea.

### 3. Instalar las dependencias
Con el entorno activado, instala todas las librer√≠as necesarias con un solo comando.
``` bash
pip install -r requirements.txt
```
### 4. Configurar las Claves de API
El proyecto necesita claves para acceder a los servicios de LLM (Google Gemini y Groq).
En la ra√≠z del proyecto, crea un fichero llamado .env.
Abre el fichero .env y a√±ade tus claves con el siguiente formato, reemplazando los valores de ejemplo:
```bash
ini
API_KEY_GEMINI="TU_API_KEY_DE_GOOGLE_AI_STUDIO"
API_KEY_GROQ="TU_API_KEY_DE_GROQ"
```

Este fichero est√° incluido en el .gitignore, por lo que tus claves secretas nunca se subir√°n al repositorio.

### 5. Ejecutar la aplicaci√≥n
¬°Ya est√° todo listo! Inicia la aplicaci√≥n Streamlit con este comando:
``` bash
streamlit run app.py
```
La aplicaci√≥n se abrir√° autom√°ticamente en una nueva pesta√±a de tu navegador.
### 6. Construir el √çndice FAISS (Solo la primera vez)
Para que la b√∫squeda funcione, necesitas crear el √≠ndice vectorial localmente.
Cuando la aplicaci√≥n se inicie, ver√°s un men√∫ en la barra lateral izquierda.
Haz clic en el bot√≥n "Construir/actualizar √çndice FAISS".
El proceso comenzar√° y puede tardar varios minutos. Descargar√° la informaci√≥n de m√°s de 280 datasets y generar√° sus embeddings.
Una vez que veas el mensaje de √©xito y los globos, el √≠ndice estar√° creado y la aplicaci√≥n estar√° 100% funcional.
üí° Uso
Escribe una consulta en lenguaje natural en el campo de texto principal (ej: "¬øD√≥nde hay aparcamientos para bicis?").
Haz clic en "Analizar Consulta".
El agente buscar√° el dataset m√°s relevante, lo analizar√° y te presentar√° visualizaciones e insights.
Puedes realizar preguntas de seguimiento sobre el dataset activo.

üìà Posibles mejoras futuras
Implementar un sistema de cach√© m√°s avanzado para los resultados de la API.
Permitir al usuario seleccionar manualmente un dataset si la b√∫squeda sem√°ntica no es precisa.
A√±adir soporte para m√°s tipos de visualizaciones.
Mejorar la gesti√≥n de memoria para datasets muy grandes.


Agradecimientos
A OpenData Val√®ncia por proporcionar los datos.
A las comunidades de Streamlit, Hugging Face y FAISS.


Una vez que tengas este fichero `README.md` guardado en tu carpeta de proyecto, solo tienes que subirlo a GitHub con estos comandos:


# A√±ade el nuevo README.md (y cualquier otro cambio)
git add README.md

# Guarda los cambios con un mensaje descriptivo
git commit -m "docs: Add professional README file"

# Sube los cambios a tu repositorio en GitHub
git push origin main
